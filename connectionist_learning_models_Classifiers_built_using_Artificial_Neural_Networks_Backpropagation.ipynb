{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonakshisharan/Machine_Learning/blob/main/connectionist_learning_models_Classifiers_built_using_Artificial_Neural_Networks_Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydpWI4rdpQeL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v_d1RAIDFltI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9c9cee-69b2-4a63-c129-0c5d3d99eba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ml dataset/abalone.data.csv')\n"
      ],
      "metadata": {
        "id": "FTHHtGmGpUx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7pPchUqph8I",
        "outputId": "a5a94e23-847c-4735-f552-07644c0fb75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
            "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
            "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
            "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
            "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
            "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
            "\n",
            "   Shell_weight  Rings  \n",
            "0         0.150     15  \n",
            "1         0.070      7  \n",
            "2         0.210      9  \n",
            "3         0.155     10  \n",
            "4         0.055      7  \n",
            "            Length     Diameter       Height  Whole_weight  Shucked_weight  \\\n",
            "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
            "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
            "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
            "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
            "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
            "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
            "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
            "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
            "\n",
            "       Viscera_weight  Shell_weight        Rings  \n",
            "count     4177.000000   4177.000000  4177.000000  \n",
            "mean         0.180594      0.238831     9.933684  \n",
            "std          0.109614      0.139203     3.224169  \n",
            "min          0.000500      0.001500     1.000000  \n",
            "25%          0.093500      0.130000     8.000000  \n",
            "50%          0.171000      0.234000     9.000000  \n",
            "75%          0.253000      0.329000    11.000000  \n",
            "max          0.760000      1.005000    29.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Sex' is a categorical variable in the dataset\n",
        "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
        "\n",
        "X = df.drop('Rings', axis=1)\n",
        "y = df['Rings']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "l84hTV7GpVAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "y_pred = lin_reg.predict(X_test_scaled)\n",
        "\n",
        "print('Linear Regression RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print('Linear Regression R^2:', r2_score(y_test, y_pred))\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "\n",
        "print('Random Forest RMSE:', np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
        "print('Random Forest R^2:', r2_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Jr2AE2prhF",
        "outputId": "7cd8007e-1f3e-41b8-f0ca-fd928ac61e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression RMSE: 2.2116130871218367\n",
            "Linear Regression R^2: 0.5481628137889262\n",
            "Random Forest RMSE: 2.2599865562542094\n",
            "Random Forest R^2: 0.5281810502563149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# If you have specific environment variables to load\n",
        "# api_key = os.getenv('API_KEY')\n"
      ],
      "metadata": {
        "id": "EiK9BFGHqh2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ml dataset/abalone.data.csv')\n"
      ],
      "metadata": {
        "id": "F2MYdEoiqj_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical columns and continuous columns\n",
        "categorical_features = ['Sex']\n",
        "continuous_features = [col for col in df.columns if col not in ['Sex', 'Rings']]\n",
        "\n",
        "# Preprocessing for continuous features: Standardization\n",
        "continuous_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Combined preprocessing for numerical and categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', continuous_transformer, continuous_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Splitting the dataset before applying transformations\n",
        "X = df.drop('Rings', axis=1)\n",
        "y = df['Rings']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply transformations\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# y needs to be converted to float for regression tasks with PyTorch\n",
        "y_train = y_train.astype(float)\n",
        "y_test = y_test.astype(float)\n"
      ],
      "metadata": {
        "id": "inY-m4KuqqOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your NumPy arrays are in float32 form for compatibility with PyTorch\n",
        "X_train_tensor = torch.tensor(X_train.astype(np.float32))\n",
        "X_test_tensor = torch.tensor(X_test.astype(np.float32))\n",
        "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
        "y_test_tensor = torch.tensor(y_test.values.astype(np.float32))\n",
        "\n",
        "# If your target variable needs to be reshaped (e.g., for regression tasks)\n",
        "y_train_tensor = y_train_tensor.view(y_train_tensor.shape[0], 1)\n",
        "y_test_tensor = y_test_tensor.view(y_test_tensor.shape[0], 1)\n"
      ],
      "metadata": {
        "id": "6OyKulrsqwmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AbaloneAgePredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AbaloneAgePredictor, self).__init__()\n",
        "        # Define the architecture here\n",
        "        self.input_layer = nn.Linear(10, 64)  # Input layer with 10 nodes as per the assignment specification\n",
        "        self.hidden_layer1 = nn.Linear(64, 32)  # First hidden layer with 64 nodes\n",
        "        self.output_layer = nn.Linear(32, 1)  # Output layer with 1 node for regression\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the network\n",
        "        x = torch.relu(self.input_layer(x))  # Activation function for first layer\n",
        "        x = torch.relu(self.hidden_layer1(x))  # Activation function for second layer\n",
        "        x = self.output_layer(x)  # No activation for the output layer in regression tasks\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "qZiXghpNq1mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AbaloneAgePredictor()\n"
      ],
      "metadata": {
        "id": "YQ8O3vSsrlvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "cWjhswiKr_3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "wlk3b1EbsFKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Create TensorDataset objects\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoader objects\n",
        "batch_size = 64  # You can adjust the batch size\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "1xEHtssZsvhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you're using a DataLoader named 'train_loader' for your training data\n",
        "num_epochs = 100  # Define the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, targets in train_loader:\n",
        "        # Step 1: Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Step 2: Backward pass and optimize\n",
        "        optimizer.zero_grad()  # Clear existing gradients\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    # Print loss every epoch or every few epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7AlTjkJsJYV",
        "outputId": "993e3a6f-67a7-43a2-be3c-e1832442c82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 11.1239\n",
            "Epoch [20/100], Loss: 9.2500\n",
            "Epoch [30/100], Loss: 5.0650\n",
            "Epoch [40/100], Loss: 18.3985\n",
            "Epoch [50/100], Loss: 4.4483\n",
            "Epoch [60/100], Loss: 7.3621\n",
            "Epoch [70/100], Loss: 8.1814\n",
            "Epoch [80/100], Loss: 29.2319\n",
            "Epoch [90/100], Loss: 14.1876\n",
            "Epoch [100/100], Loss: 6.3535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Inference without tracking gradients\n",
        "        outputs = model(X_test)\n",
        "        mse = nn.MSELoss()\n",
        "        loss = mse(outputs, y_test)\n",
        "    return loss.item()\n",
        "\n",
        "# Assuming X_test_tensor and y_test_tensor are your test data and labels as tensors\n",
        "test_loss = evaluate(model, X_test_tensor, y_test_tensor)\n",
        "print(f'Test MSE Loss: {test_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIXo3FJws2AJ",
        "outputId": "8b7bde6a-27f5-4da9-c053-3c36c1d627cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE Loss: 10.833641052246094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "tt2KeFWrvDag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spFFW_taRBtK",
        "outputId": "16865f9a-6530-4eb9-b680-fb2368c75ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adagrad (\n",
              "Parameter Group 0\n",
              "    differentiable: False\n",
              "    eps: 1e-10\n",
              "    foreach: None\n",
              "    initial_accumulator_value: 0\n",
              "    lr: 0.01\n",
              "    lr_decay: 0\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            test_loss = evaluate(model, criterion, test_loader)\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "def evaluate(model, criterion, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(test_loader)\n",
        "\n",
        "# Using SGD\n",
        "model = AbaloneAgePredictor()\n",
        "optimizer_sgd = optim.SGD(model.parameters(), lr=0.1)\n",
        "train_and_evaluate(model, optimizer_sgd, criterion, train_loader, test_loader, num_epochs=100)\n",
        "\n",
        "# Using Adagrad\n",
        "model = AbaloneAgePredictor()\n",
        "optimizer_adagrad = optim.Adagrad(model.parameters(), lr=0.01)\n",
        "train_and_evaluate(model, optimizer_adagrad, criterion, train_loader, test_loader, num_epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ0BCjp9TUxi",
        "outputId": "f8fdecfa-c709-4044-ccd7-40b742b2434f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [20/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [30/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [40/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [50/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [60/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [70/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [80/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [90/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [100/100], Train Loss: nan, Test Loss: nan\n",
            "Epoch [10/100], Train Loss: 1.8452, Test Loss: 4.8317\n",
            "Epoch [20/100], Train Loss: 3.7053, Test Loss: 4.6516\n",
            "Epoch [30/100], Train Loss: 8.8154, Test Loss: 4.5895\n",
            "Epoch [40/100], Train Loss: 2.7989, Test Loss: 4.5261\n",
            "Epoch [50/100], Train Loss: 6.3701, Test Loss: 4.5020\n",
            "Epoch [60/100], Train Loss: 2.7168, Test Loss: 4.4593\n",
            "Epoch [70/100], Train Loss: 1.7931, Test Loss: 4.4379\n",
            "Epoch [80/100], Train Loss: 3.0237, Test Loss: 4.4126\n",
            "Epoch [90/100], Train Loss: 2.6437, Test Loss: 4.4098\n",
            "Epoch [100/100], Train Loss: 3.8366, Test Loss: 4.3874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in train_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN loss encountered during training. Exiting...\")\n",
        "                return\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            test_loss = evaluate(model, criterion, test_loader)\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "def evaluate(model, criterion, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                print(\"NaN loss encountered during evaluation. Exiting...\")\n",
        "                return float('inf')  # Return infinity to indicate invalid loss\n",
        "\n",
        "    return total_loss / len(test_loader)\n",
        "\n",
        "# Using SGD\n",
        "model = AbaloneAgePredictor()\n",
        "optimizer_sgd = optim.SGD(model.parameters(), lr=0.1)\n",
        "train_and_evaluate(model, optimizer_sgd, criterion, train_loader, test_loader, num_epochs=100)\n",
        "\n",
        "# Using Adagrad\n",
        "model = AbaloneAgePredictor()\n",
        "optimizer_adagrad = optim.Adagrad(model.parameters(), lr=0.01)\n",
        "train_and_evaluate(model, optimizer_adagrad, criterion, train_loader, test_loader, num_epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ged8EOfnR0ur",
        "outputId": "ca846e18-d862-42e3-f8ef-9c903100035e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN loss encountered during training. Exiting...\n",
            "Epoch [10/100], Train Loss: 5.1802, Test Loss: 4.8475\n",
            "Epoch [20/100], Train Loss: 1.6012, Test Loss: 4.6639\n",
            "Epoch [30/100], Train Loss: 4.0529, Test Loss: 4.5903\n",
            "Epoch [40/100], Train Loss: 2.7831, Test Loss: 4.5569\n",
            "Epoch [50/100], Train Loss: 2.6741, Test Loss: 4.5240\n",
            "Epoch [60/100], Train Loss: 4.4402, Test Loss: 4.5125\n",
            "Epoch [70/100], Train Loss: 4.7123, Test Loss: 4.4962\n",
            "Epoch [80/100], Train Loss: 2.5208, Test Loss: 4.4615\n",
            "Epoch [90/100], Train Loss: 4.2704, Test Loss: 4.4424\n",
            "Epoch [100/100], Train Loss: 1.7379, Test Loss: 4.4351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-R7clTnRRQ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}